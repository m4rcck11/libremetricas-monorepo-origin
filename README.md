# Plataforma Altmetria - Backend API (v0.0.2)

API REST de alta performance desenvolvida para fornecer m√©tricas altm√©tricas de publica√ß√µes acad√™micas da Am√©rica Latina. O sistema utiliza uma arquitetura **OLAP (Online Analytical Processing)** baseada em DuckDB e arquivos Parquet, garantindo respostas r√°pidas com baixo custo computacional.

## Tecnologias

- **Runtime:** Python 3.11 (ou superior).
- **Framework Web:** FastAPI
- **Engine Anal√≠tica:** DuckDB (Zero-copy sobre Parquet)
- **Servidor de Aplica√ß√£o:** Gunicorn + Uvicorn (Production Grade)
- **Seguran√ßa & Performance:** - SlowAPI (para Rate Limiting)
  - Pydantic 
  - Cachetools (Cache em mem√≥ria L1)

## üèóÔ∏è Arquitetura

O projeto segue uma arquitetura segregada para garantir estabilidade em ambiente governamental/institucional:

1.  **API (Stateless):** Respons√°vel apenas pela leitura e agrega√ß√£o dos dados. N√£o realiza grava√ß√µes no banco principal em tempo de execu√ß√£o.
2.  **Dados (Persist√™ncia):** Os dados residem em arquivos `.parquet` e um cat√°logo DuckDB montados via Volume.
3.  **Ferramentas (ETL):** Scripts de coleta e processamento (`tools/`), atualmente desacoplados da execu√ß√£o da API.


## Executar localmente:

**Pr√©-requisitos**:
- Docker e Docker-Compose
- Python 3.11+

**Via Docker**

Configure as vari√°veis de ambiente
> O projeto inclui um .env.example. Voc√™ pode copi√°-lo e configur√°-lo manualmente ou us√°-lo para a configura√ß√£o no Kubernetes. 

**Prepare os Dados**: Depois da configura√ß√£o do container, √© preciso configurar o container etl ou rodar manualmente os programas de atualiza√ß√£o do banco de dados. Os downloads consultam nossos buckets para baixar os arquivos parquets necess√°rios para exibir a an√°lise.

4. Executar:
> docker compose up --build

A API j√° est√° dispon√≠vel em http://localhost:8000


# Deploy em produ√ß√£o (Local/Cloud)

A aplica√ß√£o √© container first. 

1. Vari√°veis de ambiente segregadas (.env)

O container precisa das seguintes vari√°veis de ambiente:

> DATA_DIR -----> Caminho absoluto dentro do container -----> /app/data (default)
> DUCKDB_PATH -----> Caminho do arquivo de banco ------> /app/data/analytics.duckdb
> CORS_ORIGINS --> Configura√ß√µes de dom√≠nio (como n√£o sei, tudo est√° liberado) -> siteoficial.com.bre
> WORKERS ------> N√∫mero de processos em paralelo no gunicorn ---> 4 (default)

## Seguran√ßa da API 

#### Rate Limiting (configur√°vel na env)
#### Read-Only Database: Conex√£o com o DuckDB √© aberta estritamente em modo leitura (read_only=True), previne corrup√ß√£o de dados por concorr√™ncia.
#### Privil√©gios: o container roda como usu√°rio (sem root).

## Manuten√ß√£o e Atualiza√ß√£o dos dados

A pasta tools/ cont√©m scripts para coleta de novas m√©tricas oriundas do CrossRef e BORI 

-> Arquivos CrossRef dispon√≠veis em: (Arquivos pesados, servidor lento)
-> Arquivos Bori dispon√≠veis em: "" ---> No alibaba Cloud (Bucket P√∫blico) (Arquivos leves)
-> Arquivos OpenAlex dispon√≠veis em: "" --> No Google Cloud (Bucket P√∫blico) (Dados gigantes, servidor "r√°pido")

### Os scripts tem tratamento de erro, retry e os dados s√£o salvos incrementalmente para contornar eventuais falhas de rede.


**Nota**: Estes scripts devem ser executados em um processo separado (Worker ou CronJob) e n√£o no container da API, para evitar degrada√ß√£o de performance. 



## Inser√ß√£o dos Dados para An√°lise via DuckDB (em casos de atualiza√ß√£o)

Com o DuckDB temos um banco de dados de 12KB. Com o DuckDB, separamos a l√≥gica do banco de dados, que j√° est√° dividido em parquets. O arquivo >analyitics.duckdb √© apenas o c√≥digo.

## Frontend
¬¥¬¥bash

cd frontend 
npm run build 

¬¥¬¥

**Configure a rota da API**: A rota da api (Frontend > src > api > AxiosConfig.js services est√° temporariamente em um dom√≠nio MARKDEV. Para utilizar localmente, insira o endere√ßo local (localhost:8000) ou o CNAME de hospedagem da API.


### O frontend ent√£o estar√° dispon√≠vel em :5173.
